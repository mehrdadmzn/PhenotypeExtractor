{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"This module contains classes and functions for creating DateBased\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pheno_package.nhsd_docker_pyspark_package.ParentPhenoClasses import PhenoTable\n",
    "from pheno_package.parametrisation_package.NHSD_pheno_parametrisation import ParameterSet\n",
    "from pheno_package.report_generator_package.PhenoReportGenerator import ReportGenerator\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DataFrameSet(PhenoTable):\n",
    "\n",
    "    def __init__(self, df_raw, production_date_str, parameter_object):\n",
    "        super().__init__(parameter_object)\n",
    "        self.RG = ReportGenerator(self.ps, self)\n",
    "        self.production_date = production_date_str\n",
    "        self.__df_raw = df_raw\n",
    "\n",
    "        self.str_df_raw = \"df_raw\"\n",
    "        self.df_linkable = None\n",
    "        self.str_df_linkable = \"df_linkable\"\n",
    "        self.df_sel = None\n",
    "        self.str_df_sel = \"df_sel\"\n",
    "        self.__df_impute = None\n",
    "        self.str_df_impute = \"df_impute\"\n",
    "        self.df_min_null = None\n",
    "        self.str_df_min_null = \"df_min_null\"\n",
    "        self.df_valid = None\n",
    "        self.str_df_valid = \"df_valid\"\n",
    "        self.df_final = None\n",
    "        self.str_df_final = \"df_final\"\n",
    "\n",
    "        # Intermediate DFs\n",
    "\n",
    "        self.temp_df_raw_null_id = None\n",
    "        self.temp_df_impute_null_id = None\n",
    "        self.temp_df_datediff = None\n",
    "\n",
    "        # Intermediate lists\n",
    "        self.temp_df_datediff_col_list = []\n",
    "\n",
    "        # null value reports\n",
    "        self.count_df_raw_null_id = 0\n",
    "        self.count_df_impute_null_id = 0\n",
    "\n",
    "    @property\n",
    "    def df_raw(self):\n",
    "        return self.__df_raw\n",
    "\n",
    "    @df_raw.setter\n",
    "    def df_raw(self, df_raw):\n",
    "        self.__df_raw = df_raw\n",
    "\n",
    "    @property\n",
    "    def df_impute(self):\n",
    "        return self.__df_impute\n",
    "\n",
    "    @df_impute.setter\n",
    "    def df_impute(self, df_impute):\n",
    "        self.__df_impute = df_impute\n",
    "\n",
    "    @staticmethod\n",
    "    def multi_event_date_null_handling(df, evdt_col_list, new_col_name, full_report=True):\n",
    "        report_list = []\n",
    "        df_out = df\n",
    "        for col_name in evdt_col_list[1:]:\n",
    "            if full_report:\n",
    "                count_null = df_out.filter((F.col(col_name).isNotNull()) & (F.col(new_col_name).isNull())).count()\n",
    "                if count_null > 0:\n",
    "                    report_list.append(\n",
    "                        f'''{count_null} null {new_col_name} values replaced with non-null values of {col_name}''')\n",
    "            df_out = df_out.withColumn(new_col_name,\n",
    "                                       F.when(((F.col(col_name).isNotNull()) & (F.col(new_col_name).isNull())),\n",
    "                                              F.col(col_name)).otherwise(F.col(new_col_name)))\n",
    "        return df_out, report_list\n",
    "\n",
    "    @staticmethod\n",
    "    def drop_remaining_null_dates(df, index_col, new_evdt_col, full_report=True):\n",
    "        report_list = []\n",
    "        df_out = df\n",
    "        df_invalid = df_out.filter(F.col(new_evdt_col).isNull())\n",
    "        if full_report:\n",
    "            invalid_count = df_invalid.count()\n",
    "            report_list.append(f'''Remaining {invalid_count} records with null dates are dropped.''')\n",
    "        # df_out = df_out.join(df_invalid, on=[index_col], how=\"left_anti\")\n",
    "        df_out = df_out.filter(F.col(new_evdt_col).isNotNull())\n",
    "        return df_out, report_list\n",
    "\n",
    "    @staticmethod\n",
    "    def multi_event_date_endpoint_correction(df, evdt_col_list, new_col_name, start_date, end_date,\n",
    "                                             full_report=True):\n",
    "        report_list = []\n",
    "        diff_cols_list = []\n",
    "        df_datediff = df\n",
    "        df_out = df\n",
    "        # To avoid changing the main new_col_nme in the loop\n",
    "        temp_col_list = []\n",
    "        for index, item in enumerate(evdt_col_list):\n",
    "            temp_col_list.append(f'''{item}_{index}''')\n",
    "        df_out = df_out.withColumn(temp_col_list[0], F.col(new_col_name))\n",
    "\n",
    "        for col_index, col_name in enumerate(evdt_col_list):\n",
    "            count_invalid = df_out.filter((\n",
    "                    ((F.col(temp_col_list[col_index]) < start_date) | (F.col(temp_col_list[col_index]) > end_date)) &\n",
    "                    ((F.col(col_name) >= start_date) & (F.col(col_name) <= end_date))\n",
    "            )).count()\n",
    "\n",
    "            if count_invalid > 0:\n",
    "                report_list.append(f'''{count_invalid} invalid {new_col_name} values will be replaced with valid \n",
    "                dates of {col_name}''')\n",
    "            df_out = df_out.withColumn(temp_col_list[col_index], F.when((((F.col(\n",
    "                temp_col_list[col_index]) < start_date) | (F.col(temp_col_list[col_index]) > end_date)) & (\n",
    "                                                                                 (F.col(col_name) >= start_date) & (\n",
    "                                                                                 F.col(col_name) <= end_date))),\n",
    "                                                                        F.col(col_name)).otherwise(\n",
    "                F.col(temp_col_list[col_index])))\n",
    "\n",
    "            if col_index + 1 < len(evdt_col_list):\n",
    "                df_out = df_out.withColumn(temp_col_list[col_index + 1], F.col(temp_col_list[col_index]))\n",
    "            else:\n",
    "                df_out = df_out.withColumn(new_col_name, F.col(temp_col_list[col_index]))\n",
    "        for index, item in enumerate(evdt_col_list):\n",
    "            df_out = df_out.drop(temp_col_list[index])\n",
    "\n",
    "        if full_report:\n",
    "            for col_name in evdt_col_list:\n",
    "                diff_col = f'''datediff_{col_name}_and_{new_col_name}'''\n",
    "                df_datediff = df_datediff.withColumn(diff_col, F.datediff(new_col_name, col_name))\n",
    "                diff_cols_list.append(diff_col)\n",
    "        return df_out, report_list, df_datediff, diff_cols_list\n",
    "\n",
    "    @staticmethod\n",
    "    def drop_remaining_invalid_dates(df, index_col, new_evdt_col, start_date, end_date, full_report):\n",
    "        report_list = []\n",
    "        df_out = df\n",
    "        df_invalid = df_out.filter((F.col(new_evdt_col) < start_date) | (F.col(new_evdt_col) > end_date))\n",
    "        if full_report:\n",
    "            invalid_count = df_invalid.count()\n",
    "            report_list.append(f'''Remaining {invalid_count} records with invalid dates are dropped.''')\n",
    "        # df_out = df.join(df_invalid, on = [index_col], how = \"left_anti\")\n",
    "\n",
    "        df_out = df_out.filter((F.col(new_evdt_col) >= start_date) & (F.col(new_evdt_col) <= end_date))\n",
    "        return df_out, report_list\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def event_pheno_extractor(df_raw, param_yaml, table_tag):\n",
    "    PS = ParameterSet(param_yaml, table_tag)\n",
    "    DFS = DataFrameSet(df_raw, PS.production_date_str, PS)\n",
    "    DFS.RG.dataframe_set_initialisation()\n",
    "\n",
    "    DFS = DataFrameSet(df_raw, PS.production_date_str, PS)\n",
    "    DFS.RG.initial_report()\n",
    "    DFS.RG.report_counts_df_raw()\n",
    "\n",
    "    print(f'''#### counting null IDs''')\n",
    "    DFS.count_df_raw_null_id, DFS.temp_df_raw_null_id = DFS.RG.count_null(DFS.df_raw, PS.index_col)\n",
    "\n",
    "    DFS.RG.report_null_col(DFS.df_raw, DFS.str_df_raw, PS.index_col, DFS.count_df_raw_null_id)\n",
    "\n",
    "    DFS.df_linkable = DFS.df_raw\n",
    "    if PS.drop_null_ids:\n",
    "        if DFS.count_df_raw_null_id > 0:\n",
    "            DFS.RG.report_drops(DFS.count_df_raw_null_id, DFS.str_df_linkable, PS.index_col)\n",
    "            DFS.df_linkable = DFS.df_raw.filter(F.col(PS.index_col).isNotNull())\n",
    "\n",
    "\n",
    "        else:\n",
    "            print(f'''no null {PS.index_col} is found''')\n",
    "    DFS.RG.report_counts(DFS.df_linkable, DFS.str_df_linkable, PS.index_col)\n",
    "\n",
    "    # Todo add more reports\n",
    "\n",
    "    DFS.df_sel = DFS.df_linkable\n",
    "    DFS.df_sel = DFS.df_sel.select([PS.index_col] + PS.evdt_col_list)\n",
    "\n",
    "    # Todo more reports\n",
    "    print(\"df_impute\")\n",
    "    DFS.df_impute = DFS.df_sel.withColumn(PS.evdt_pheno, F.col(PS.evdt_col_raw))\n",
    "    DFS.count_df_impute_null_id, DFS.temp_df_impute_null_id = DFS.RG.count_null(DFS.df_impute,\n",
    "                                                                                PS.index_col)\n",
    "    if PS.impute_multi_col_null_dates:\n",
    "        DFS.df_impute, report_list = DFS.multi_event_date_null_handling(DFS.df_impute, PS.evdt_col_list, PS.evdt_pheno,\n",
    "                                                                        full_report=PS.full_report)\n",
    "        print(*report_list, sep=\"\\n\")\n",
    "\n",
    "    print(f'''### Final null check''')\n",
    "    DFS.RG.report_null_col(DFS.df_impute, DFS.str_df_impute, PS.evdt_pheno, DFS.count_df_impute_null_id)\n",
    "    print(\"df_min_null\")\n",
    "    DFS.df_min_null = DFS.df_impute\n",
    "    report_list = []\n",
    "    if PS.drop_remaining_null_dates:\n",
    "        DFS.df_min_null, report_list = DFS.drop_remaining_null_dates(DFS.df_impute, PS.index_col, PS.evdt_pheno,\n",
    "                                                                     PS.full_report)\n",
    "    print(*report_list, sep=\"\\n\")\n",
    "    print(f'''\\n###### check dates that are less than {PS.start_date_qc} and larget than {PS.end_date_qc}''')\n",
    "    DFS.RG.report_invalid_dates(DFS.df_min_null, DFS.str_df_min_null, PS.evdt_pheno, PS.start_date_qc, PS.end_date_qc)\n",
    "\n",
    "    # Cache\n",
    "    if PS.spark_cache_midway:\n",
    "        print(f'''\\n Chaching df_min_null''')\n",
    "        DFS.df_min_null.cache()\n",
    "\n",
    "    # df valid\n",
    "    # Todo more report\n",
    "    print(\"df_valid\")\n",
    "    DFS.df_valid = DFS.df_min_null\n",
    "    if PS.impute_multi_col_invalid_dates:\n",
    "        print(f'''#### out-of-range dates are being corrected''')\n",
    "        DFS.df_valid, report_list, DFS.temp_df_datediff, DFS.temp_df_datediff_col_list = DFS.multi_event_date_endpoint_correction(\n",
    "            DFS.df_valid, PS.evdt_col_list, PS.evdt_pheno, PS.start_date_qc, PS.end_date_qc, full_report=PS.full_report)\n",
    "\n",
    "        print(*report_list, sep=\"\\n\")\n",
    "\n",
    "    # Todo box plot report\n",
    "    print(f'''final check on invalid dates''')\n",
    "    DFS.RG.report_invalid_dates(DFS.df_valid, DFS.str_df_valid, PS.evdt_pheno, PS.start_date_qc, PS.end_date_qc)\n",
    "    print(f'''Making df_final''')\n",
    "    report_list = []\n",
    "    DFS.df_final = DFS.df_valid\n",
    "    if PS.drop_remaining_invalid_dates:\n",
    "        print(f''''### Invalid dates will be dropped ''')\n",
    "        DFS.df_final, report_list = DFS.drop_remaining_invalid_dates(DFS.df_final, PS.index_col, PS.evdt_pheno,\n",
    "                                                                     PS.start_date_qc, PS.end_date_qc,\n",
    "                                                                     full_report=PS.full_report)\n",
    "    print(*report_list, sep=\"\\n\")\n",
    "    print(\"Done!\")\n",
    "    return DFS, PS\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
