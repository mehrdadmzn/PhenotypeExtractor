{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\"\"\"This module contains parent classes for phenotype data collections\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import DataFrame\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def first_eventdate_extractor(df: DataFrame, index_col, date_col):\n",
    "    window_spec = Window.partitionBy(df[index_col]).orderBy(F.col(date_col).asc_nulls_last())\n",
    "    df_rank = df.withColumn(\"rank_col\", F.row_number().over(window_spec))\n",
    "    df_out = df_rank.filter(F.col(\"rank_col\") == 1).drop(\"rank_col\")\n",
    "    return (df_out)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "def concat_nonnull_eventdate_extractor(df: DataFrame, index_col, date_col):\n",
    "    window_spec = Window.partitionBy(df[index_col]).orderBy(F.col(date_col).asc_nulls_last())\n",
    "    df_out = df.withColumn(\"rank_col\", F.row_number().over(window_spec))\n",
    "    df_out = df_out.withColumn(\"list_all\", F.collect_list(date_col).over(window_spec))\n",
    "    df_first_infection = df_out.filter(F.col(\"rank_col\") == 1).drop(\"rank_col\")\n",
    "    df_out = df_out.withColumn(\"list_all\", F.array_sort(\"list_all\"))\n",
    "    window_rank = Window.partitionBy(df_out[index_col]).orderBy(F.col(\"rank_col\").desc_nulls_last())\n",
    "    df_out = df_out.withColumn(\"keep_rank\", F.row_number().over(window_rank))\n",
    "    df_out = df_out.filter(F.col(\"keep_rank\") == 1)\n",
    "    # df_out = df_out.withColumn(\"count_null\", F.col(\"rank_col\") - F.size(F.col(\"list_all\")))\n",
    "    df_out = df_out.withColumn(\"list_distinct\", F.array_distinct(F.col(\"list_all\")))\n",
    "    df_out = df_out.withColumn(\"count_distinct\", F.size(F.col(\"list_distinct\")))\n",
    "    df_out = df_out.withColumnRenamed(\"rank_col\", \"count_all\").drop(\"keep_rank\").drop(date_col)\n",
    "\n",
    "    return df_out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class PhenoTable:\n",
    "    def __init__(self, parameter_object):\n",
    "        self.ps = parameter_object\n",
    "        # pheno DFs\n",
    "        self.__pheno_df_basic = None\n",
    "        self.__pheno_df_full = None\n",
    "        self.__pheno_df_json = None\n",
    "        self.__isin_flag_col = f'''isin_{self.ps.table_tag}'''\n",
    "\n",
    "    @property\n",
    "    def pheno_df_basic(self):\n",
    "        return self.__pheno_df_basic\n",
    "\n",
    "    @property\n",
    "    def pheno_df_full(self):\n",
    "        return self.__pheno_df_full\n",
    "\n",
    "    @property\n",
    "    def pheno_df_json(self):\n",
    "        return self.__pheno_df_json\n",
    "\n",
    "    @pheno_df_basic.setter\n",
    "    def pheno_df_basic(self, saved_basic_df):\n",
    "        self.__pheno_df_basic = saved_basic_df\n",
    "\n",
    "    @pheno_df_full.setter\n",
    "    def pheno_df_full(self, saved_full_df):\n",
    "        self.__pheno_df_full = saved_full_df\n",
    "\n",
    "    @pheno_df_json.setter\n",
    "    def pheno_df_json(self, saved_json_df):\n",
    "        self.__pheno_df_json = saved_json_df\n",
    "\n",
    "    def extract_basic_pheno_df(self, add_isin_flag=True):\n",
    "        self.pheno_df_basic = first_eventdate_extractor(\n",
    "            self.df_final.select([self.ps.index_col, self.ps.evdt_pheno]),\n",
    "            index_col=self.ps.index_col, date_col=self.ps.evdt_pheno)\n",
    "\n",
    "    def extract_full_pheno_df(self):\n",
    "        self.pheno_df_full = concat_nonnull_eventdate_extractor(\n",
    "            self.df_final.select([self.ps.index_col, self.ps.evdt_pheno]), index_col=self.ps.index_col,\n",
    "            date_col=self.ps.evdt_pheno)\n",
    "\n",
    "    @staticmethod\n",
    "    def explode_array_col(pheno_df_full, array_col, index_col, new_col_name):\n",
    "        if pheno_df_full is not None:\n",
    "            return pheno_df_full.select(index_col, F.explode(F.col(array_col)).alias(new_col_name))\n",
    "\n",
    "    def return_long_event_df(self, list_events=\"distinct\", add_isin_flag=True, include_nulls=False):\n",
    "        df_long = None\n",
    "        if list_events == \"all\":\n",
    "            df_long = self.explode_array_col(\"list_all\")\n",
    "        elif list_events == \"distinct\":\n",
    "            df_long = self.explode_array_col(\"list_distinct\")\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if df_long is not None:\n",
    "            df_long = df_long.withColumnRenamed(\"col\", self.ps.evdt_pheno)\n",
    "            if add_isin_flag:\n",
    "                df_long = df_long.withColumn(self.__isin_flag_col, F.lit(1))\n",
    "        return df_long\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
